{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T23:04:22.091756Z",
     "iopub.status.busy": "2021-11-12T23:04:22.090886Z",
     "iopub.status.idle": "2021-11-12T23:04:22.297175Z",
     "shell.execute_reply": "2021-11-12T23:04:22.295949Z",
     "shell.execute_reply.started": "2021-11-12T23:04:22.091710Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is a \"never submitted script\" for the RSNA BRAIN TUMOR\n",
    "# CLASSIFICATION - Kaggle competition.\n",
    "#\n",
    "# I gave up on this project because I could not create a model\n",
    "# that seemed to learn anything from the data. But when I saw\n",
    "# the final results and understood that in the end nobody really\n",
    "# could, I decided to give it a try in a \"late submission\".\n",
    "#\n",
    "# Unfortunatly I spent too much time on other projects and the\n",
    "# time window allowing late submissions closed before I could make\n",
    "# that submission.\n",
    "#\n",
    "# That's too bad because I had created a complexe (or messy^^)\n",
    "# process that succeded more or less in identifying and extracting\n",
    "# the tumor zone in the 3d images. And it would have been interesting\n",
    "# to know if it helped or not in this complicated competition.\n",
    "\n",
    "\n",
    "#####################\n",
    "# Python librairies #\n",
    "#####################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "\n",
    "import nibabel as nib\n",
    "import imgaug.augmenters as iaa\n",
    "import pydicom as dicom\n",
    "import SimpleITK as sitk\n",
    "import random\n",
    "\n",
    "from glob import glob\n",
    "from time import time\n",
    "from PIL import Image\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from tqdm import tqdm\n",
    "from numpy.random import seed\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv3D, Input, BatchNormalization,\\\n",
    "    Reshape, MaxPool3D, Dense, Dropout, Activation, Conv2D,\\\n",
    "    GlobalMaxPool2D, MaxPool2D, Concatenate, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from IPython.display import FileLink\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score,\\\n",
    "    plot_roc_curve\n",
    "\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "\n",
    "seed(48)\n",
    "set_seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T23:05:30.517847Z",
     "iopub.status.busy": "2021-11-12T23:05:30.517356Z",
     "iopub.status.idle": "2021-11-12T23:05:30.856122Z",
     "shell.execute_reply": "2021-11-12T23:05:30.855192Z",
     "shell.execute_reply.started": "2021-11-12T23:05:30.517795Z"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Constants définitions #\n",
    "#########################\n",
    "\n",
    "INPUT = \"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/\"\n",
    "OUT = \"/kaggle/working\"\n",
    "TRAIN_PATH = INPUT + \"/\" + sorted(os.listdir(INPUT))[2]\n",
    "TEST_PATH = INPUT + \"/\" + sorted(os.listdir(INPUT))[1]\n",
    "OUT_TRAIN = \"train\"\n",
    "OUT_VAL = \"val\"\n",
    "OUT_TEST = \"test\"\n",
    "\n",
    "random.seed(48)\n",
    "\n",
    "# Preprocessing parameters\n",
    "NB_SAMPLES = 12  # number of kept images PER MODALITY\n",
    "SIZE_TEMP = (512, 512)  # size in the 3d images\n",
    "SIZE = (150, 150)  # size of the final 3d images for medelization\n",
    "MODS = sorted([\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"])  # list of used modality\n",
    "NB_MOD = len(MODS)\n",
    "THRESHOLD = 220  # threshold pixel value when filtering for finding zoi\n",
    "RABOTAGE = 40  # number of pixel on the image sides we get rid of\n",
    "ZOOM = 1.2  # zoom image transformation parameter\n",
    "BATCH = 8\n",
    "\n",
    "# Data generator parameters\n",
    "LIST_ITERATION = 7  # number of iterations per epochs for the generator\n",
    "\n",
    "# Define our reference image for the \"resample\" function\n",
    "reference_image_path = TRAIN_PATH + \"/00143/T1w\"\n",
    "reader = sitk.ImageSeriesReader()\n",
    "dicom_names = reader.GetGDCMSeriesFileNames(reference_image_path)\n",
    "reader.SetFileNames(dicom_names)\n",
    "ref_image = reader.Execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T23:37:07.417115Z",
     "iopub.status.busy": "2021-11-12T23:37:07.416675Z",
     "iopub.status.idle": "2021-11-12T23:37:07.714838Z",
     "shell.execute_reply": "2021-11-12T23:37:07.713809Z",
     "shell.execute_reply.started": "2021-11-12T23:37:07.417067Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Preprocessing & modelization functions #\n",
    "##########################################\n",
    "\n",
    "def pertinent_slices(im3d, seuil=0.6):\n",
    "    \"\"\"\n",
    "    Find if the image brain is important enough.\n",
    "    \"\"\"\n",
    "    for i in range(im3d.shape[0]):\n",
    "\n",
    "        if np.mean(im3d[i]) != 0:\n",
    "\n",
    "            mk = im3d[i] > 0\n",
    "\n",
    "            coords = np.argwhere(mk)\n",
    "            y0, _ = coords.min(axis=0)\n",
    "            y1, _ = coords.max(axis=0) + 1\n",
    "\n",
    "            haut = y1-y0\n",
    "\n",
    "            if haut/SIZE_TEMP[0] < seuil:\n",
    "\n",
    "                im3d[i, :, :] = 0\n",
    "\n",
    "    return im3d\n",
    "\n",
    "\n",
    "def zoom(im3d):\n",
    "    \"\"\"\n",
    "    This function apply a zoom transformation to each slice of a 3d image\n",
    "    \"\"\"\n",
    "    scale = iaa.Affine(scale=(ZOOM))\n",
    "\n",
    "    new_image = np.zeros(im3d.shape)\n",
    "\n",
    "    for i in range(im3d.shape[0]):\n",
    "\n",
    "        img = im3d[i, :, :]\n",
    "        img = scale.augment_image(img)\n",
    "        new_image[i] = img\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def rabote(image, rabotage=RABOTAGE):\n",
    "    \"\"\"\n",
    "    Get rid of the edges of brain image where we often find bright pixels.\n",
    "    \"\"\"\n",
    "    temp_image = image.copy()\n",
    "\n",
    "    for h in range(temp_image.shape[0]):\n",
    "\n",
    "        for i in range(temp_image.shape[1]):\n",
    "\n",
    "            if np.mean(temp_image[h, i, :]) != 0:\n",
    "\n",
    "                vector = temp_image[h, i, :]\n",
    "                temp_mask = vector > 0\n",
    "                temp_coords = np.argwhere(temp_mask)\n",
    "\n",
    "                mini = temp_coords.min(axis=0)\n",
    "                maxi = temp_coords.max(axis=0)\n",
    "                temp_image[h, i, : int(mini + rabotage/2)] = 0\n",
    "                temp_image[h, i, int(maxi-rabotage/2):] = 0\n",
    "\n",
    "    for h in range(temp_image.shape[0]):\n",
    "\n",
    "        for i in range(temp_image.shape[2]):\n",
    "\n",
    "            if np.mean(temp_image[h, :, i]) != 0:\n",
    "\n",
    "                vector = temp_image[h, :, i]\n",
    "                temp_mask = vector > 0\n",
    "                temp_coords = np.argwhere(temp_mask)\n",
    "\n",
    "                mini = temp_coords.min(axis=0)\n",
    "                maxi = temp_coords.max(axis=0)\n",
    "                temp_image[h, : int(mini + rabotage), i] = 0\n",
    "                temp_image[h, int(maxi-rabotage):, i] = 0\n",
    "\n",
    "    return temp_image\n",
    "\n",
    "\n",
    "def zoi_cube(flair_image, ID, threshold=THRESHOLD, rabotage=RABOTAGE):\n",
    "    \"\"\"\n",
    "    Function that tries to identify the tumoral zone in the 3d images.\n",
    "    It returns a \"zoi\".\n",
    "    \"\"\"\n",
    "    bool_zoom = False\n",
    "    temp_image = flair_image.copy()\n",
    "    temp_image = pertinent_slices(temp_image)\n",
    "\n",
    "    if np.mean(temp_image) == 0:\n",
    "\n",
    "        temp_image = flair_image.copy()\n",
    "        temp_image = zoom(temp_image)\n",
    "        temp_image = pertinent_slices(temp_image)\n",
    "        bool_zoom = True\n",
    "\n",
    "    if np.mean(temp_image) == 0:\n",
    "\n",
    "        temp_image = flair_image.copy()\n",
    "        temp_image = pertinent_slices(temp_image, 0.5)\n",
    "        bool_zoom = False\n",
    "\n",
    "    temp_image = rabote(temp_image)\n",
    "\n",
    "    masked = np.ma.masked_equal(temp_image, 0)\n",
    "    mean_image = np.mean(masked, axis=0).astype(np.uint8)\n",
    "\n",
    "    eroded = cv2.erode(mean_image, None, iterations=6)\n",
    "    eroded = normalize_img(eroded).astype(np.uint8)\n",
    "    mask = eroded > threshold\n",
    "\n",
    "    coords = np.argwhere(mask)\n",
    "\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0) + 1\n",
    "\n",
    "    x_center = x0 + int(0.5*(x1-x0))\n",
    "    y_center = y0 + int(0.5*(y1-y0))\n",
    "\n",
    "    x_min = x_center - int(SIZE[0]/2)\n",
    "    x_max = x_center + int(SIZE[0]/2)\n",
    "    y_min = y_center - int(SIZE[0]/2)\n",
    "    y_max = y_center + int(SIZE[0]/2)\n",
    "\n",
    "    # cas limites\n",
    "    if x_min < 0:\n",
    "\n",
    "        x_min = 0\n",
    "        x_max = SIZE[0]\n",
    "\n",
    "    elif x_max > SIZE_TEMP[0]-1:\n",
    "\n",
    "        x_min = SIZE_TEMP[0]-SIZE[0]\n",
    "        X_max = SIZE_TEMP[0]\n",
    "\n",
    "    elif y_min < 0:\n",
    "\n",
    "        y_min = 0\n",
    "        y_max = SIZE[0]\n",
    "\n",
    "    elif y_max > SIZE_TEMP[0]-1:\n",
    "\n",
    "        y_min = SIZE_TEMP[0]-SIZE[0]\n",
    "        y_max = SIZE_TEMP[0]\n",
    "\n",
    "    temp_image_filtered = normalize_img(temp_image).astype(np.uint8)\n",
    "    temp_image_filtered = temp_image_filtered[:, y_min:y_max, x_min:x_max]\\\n",
    "        .astype(np.uint8)\n",
    "\n",
    "    if np.max(temp_image_filtered) <= threshold:\n",
    "\n",
    "        temp_image_filtered = normalize_img(temp_image_filtered)\n",
    "\n",
    "    msk = temp_image_filtered >= threshold\n",
    "    coor = np.argwhere(msk)\n",
    "\n",
    "    z0, _, _ = coor.min(axis=0)\n",
    "    z1, _, _ = coor.max(axis=0) + 1\n",
    "\n",
    "    zoi = (x_min, x_max, y_min, y_max, z0, z1, bool_zoom)\n",
    "\n",
    "    return zoi\n",
    "\n",
    "\n",
    "def create_dataframe(path, mods):\n",
    "    \"\"\"\n",
    "    Create a reference dataframe.\n",
    "    \"\"\"\n",
    "    chemins = []\n",
    "    patients = []\n",
    "    scans = []\n",
    "\n",
    "    liste = sorted(glob(path + \"/*/*\"))\n",
    "\n",
    "    for elt in liste:\n",
    "\n",
    "        chemins.append(elt)\n",
    "        patients.append(elt.split(\"/\")[-2])\n",
    "        scans.append(elt.split(\"/\")[-1])\n",
    "\n",
    "    df = pd.DataFrame(list(zip(chemins, patients, scans)),\n",
    "                      columns=[\"chemins\", \"BraTS21ID\", \"scan type\"])\n",
    "\n",
    "    df = df[df[\"scan type\"].isin(mods)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_train_df(df):\n",
    "    \"\"\"\n",
    "    Get rid of bad data.\n",
    "    \"\"\"\n",
    "    liste_del = ['00123', '00109', '00709']\n",
    "\n",
    "    for k in liste_del:\n",
    "        df = df.loc[df[\"BraTS21ID\"] != k]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_dicts(path_to_csv):\n",
    "    \"\"\"\n",
    "    Create a dict object with which we'll later build our labels.\n",
    "    \"\"\"\n",
    "    df_labels = pd.read_csv(path_to_csv)\n",
    "    dico_labels = {}\n",
    "\n",
    "    for r in df_labels.iterrows():\n",
    "        dico_labels[str(r[1][0])] = str(r[1][1])\n",
    "\n",
    "    return dico_labels\n",
    "\n",
    "\n",
    "def zoi_crop(img3d, zoi):\n",
    "    \"\"\"\n",
    "    We use the \"zoi\" determined sooner to crop the 3d image.\n",
    "    \"\"\"\n",
    "    slices = zoi[5] - zoi[4]\n",
    "    bool_zoom = zoi[6]\n",
    "\n",
    "    if slices < NB_SAMPLES:\n",
    "\n",
    "        missing = NB_SAMPLES-slices\n",
    "\n",
    "        extension = int(missing//2)\n",
    "        lim_haute = zoi[4] - extension\n",
    "\n",
    "        if missing % 2 == 0:\n",
    "\n",
    "            lim_basse = zoi[5] + extension\n",
    "\n",
    "        else:\n",
    "\n",
    "            lim_basse = zoi[5] + extension + 1\n",
    "\n",
    "        if lim_haute < 0:\n",
    "\n",
    "            lim_haute = 0\n",
    "            lim_basse = NB_SAMPLES\n",
    "\n",
    "        if lim_basse > img3d.shape[0] - 1:\n",
    "\n",
    "            lim_basse = img3d.shape[0] - 1\n",
    "            lim_haute = img3d.shape[0] - (NB_SAMPLES + 1)\n",
    "\n",
    "    elif slices > NB_SAMPLES:\n",
    "\n",
    "        surplus = slices - NB_SAMPLES\n",
    "        reduction = int(surplus//2)\n",
    "        lim_haute = zoi[4] + reduction\n",
    "\n",
    "        if surplus % 2 == 0:\n",
    "\n",
    "            lim_basse = zoi[5] - reduction\n",
    "\n",
    "        else:\n",
    "\n",
    "            lim_basse = zoi[5] - (reduction + 1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        lim_haute = zoi[4]\n",
    "        lim_basse = zoi[5]\n",
    "\n",
    "    if bool_zoom:\n",
    "\n",
    "        img3d = zoom(img3d)\n",
    "\n",
    "    img3d = img3d[lim_haute: lim_basse, zoi[2]:zoi[3], zoi[0]:zoi[1]]\n",
    "\n",
    "    return img3d.astype(np.uint8)\n",
    "\n",
    "\n",
    "def resize_3d(img3d, size):\n",
    "    \"\"\"\n",
    "    Resize 3d images.\n",
    "    \"\"\"\n",
    "    sh = img3d.shape\n",
    "    new_image_3D = np.zeros((sh[0], size[0], size[1]))\n",
    "\n",
    "    for i in range(sh[0]):\n",
    "\n",
    "        im = Image.fromarray(img3d[i, :, :])\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.resize((size))\n",
    "        im = np.array(im)\n",
    "        new_image_3D[i] = im\n",
    "\n",
    "    return new_image_3D\n",
    "\n",
    "\n",
    "def crop_center(img3d):\n",
    "    \"\"\"\n",
    "    Center-crop 3d images that are not square.\n",
    "    \"\"\"\n",
    "    crop = iaa.size.CropToSquare(position=\"center\")\n",
    "\n",
    "    mini = min(img3d.shape[1], img3d.shape[2])\n",
    "    new_image_3D = np.zeros((img3d.shape[0], mini, mini))\n",
    "\n",
    "    for i in range(img3d.shape[0]):\n",
    "\n",
    "        temp = img3d[i, :, :]\n",
    "        temp = crop.augment_image(temp)\n",
    "        new_image_3D[i] = temp\n",
    "\n",
    "    return new_image_3D\n",
    "\n",
    "\n",
    "def normalize_img(img3d):\n",
    "    \"\"\"\n",
    "    Normalize 3d images.\n",
    "    \"\"\"\n",
    "    img3d = img3d - np.min(img3d)\n",
    "    if np.max(img3d) != 0:\n",
    "        img3d = img3d / np.max(img3d)\n",
    "    img3d = (img3d * 255).astype(np.uint8)\n",
    "    return img3d\n",
    "\n",
    "\n",
    "def resample(image3D, ref_image):\n",
    "    \"\"\"\n",
    "    Re-orient 3d images according to the reference image.\n",
    "    \"\"\"\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(ref_image)\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resampler.SetTransform(sitk.AffineTransform(ref_image.GetDimension()))\n",
    "    resampler.SetOutputSpacing(ref_image.GetSpacing())\n",
    "    resampler.SetSize(ref_image.GetSize())\n",
    "    resampler.SetOutputDirection(ref_image.GetDirection())\n",
    "    resampler.SetOutputOrigin(ref_image.GetOrigin())\n",
    "    resampler.SetDefaultPixelValue(image3D.GetPixelIDValue())\n",
    "    resampled_image_3D = resampler.Execute(image3D)\n",
    "\n",
    "    return resampled_image_3D\n",
    "\n",
    "\n",
    "def preprocessing(df_source, target, mods=MODS):\n",
    "    \"\"\"\n",
    "    Whole preprocessing function.\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "\n",
    "    if os.path.isdir(target):\n",
    "        shutil.rmtree(target)\n",
    "        os.mkdir(target)\n",
    "\n",
    "    else:\n",
    "        os.mkdir(target)\n",
    "\n",
    "    liste_IDs = sorted(set(df_source[\"BraTS21ID\"].values.tolist()))\n",
    "    target_path = target\n",
    "\n",
    "    for ix, ID in enumerate(liste_IDs):\n",
    "\n",
    "        if ix != 0:\n",
    "            if ix % 50 == 0:\n",
    "                print(f\"Traitement {ix}ème patient au bout de\\\n",
    "                {time()-start:.0f} secondes\")\n",
    "\n",
    "        dim_ID = str(int(ID))\n",
    "        target_name = dim_ID\n",
    "\n",
    "        image_3D = np.zeros((NB_SAMPLES * NB_MOD, SIZE[0], SIZE[1]))\n",
    "        zoi = ()\n",
    "\n",
    "        for i, mod in enumerate(mods):\n",
    "\n",
    "            row = df_source[(df_source[\"BraTS21ID\"] == ID) &\n",
    "                            (df_source[\"scan type\"] == mod)]\n",
    "\n",
    "            path_dcm = row[\"chemins\"].values[0]\n",
    "            reader = sitk.ImageSeriesReader()\n",
    "            dicom_names = reader.GetGDCMSeriesFileNames(path_dcm)\n",
    "            reader.SetFileNames(dicom_names)\n",
    "            im3D = reader.Execute()\n",
    "            new_img3D = resample(im3D, ref_image)\n",
    "            array_3D = normalize_img(sitk.GetArrayFromImage(new_img3D))\n",
    "\n",
    "            if array_3D.shape[1] != array_3D.shape[2]:\n",
    "\n",
    "                array_3D = crop_center(array_3D)\n",
    "\n",
    "            array_3D = resize_3d(array_3D, SIZE_TEMP).astype(np.uint8)\n",
    "\n",
    "            if mod == \"FLAIR\":\n",
    "\n",
    "                zoi = zoi_cube(array_3D, ID)\n",
    "\n",
    "            array_3D = zoi_crop(array_3D, zoi)\n",
    "            image_3D[i*NB_SAMPLES:(i+1)*NB_SAMPLES, :, :] = array_3D\n",
    "\n",
    "        image_3D = normalize_img(image_3D).astype(np.uint8)\n",
    "        np.save(target_path + \"/\" + target_name, image_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T23:56:36.683553Z",
     "iopub.status.busy": "2021-11-12T23:56:36.683272Z",
     "iopub.status.idle": "2021-11-12T23:56:36.910967Z",
     "shell.execute_reply": "2021-11-12T23:56:36.909969Z",
     "shell.execute_reply.started": "2021-11-12T23:56:36.683524Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Data generator with augmentation #\n",
    "####################################\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    # Generates data\n",
    "    def __init__(self,\n",
    "                 list_IDs,\n",
    "                 labels,\n",
    "                 source,\n",
    "                 batch_size,\n",
    "                 nb_samples,\n",
    "                 moda,\n",
    "                 shuffle=True,\n",
    "                 divise=True,\n",
    "                 aug=True,\n",
    "                 train=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.nb_samples = nb_samples\n",
    "        self.moda = moda\n",
    "        self.shuffle = shuffle\n",
    "        self.source = source\n",
    "        self.divise = divise\n",
    "        self.aug = aug\n",
    "        self.train = train\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        if self.train:\n",
    "\n",
    "            y = [int(self.labels[k]) for k in indexes]\n",
    "            y = np.array(y)\n",
    "\n",
    "            X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "            return X, y\n",
    "\n",
    "        else:\n",
    "\n",
    "            X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "            return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "        if self.shuffle:\n",
    "\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "\n",
    "        if self.divise:\n",
    "\n",
    "            X = np.empty((self.batch_size, len(self.moda), self.nb_samples,\n",
    "                          SIZE[0], SIZE[1]))\n",
    "\n",
    "        else:\n",
    "\n",
    "            X = np.empty((self.batch_size, len(self.moda) * self.nb_samples,\n",
    "                          SIZE[0], SIZE[1]))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            image = np.load(self.source + '/' + ID)\n",
    "            indices = []\n",
    "            indices_base = [a*self.nb_samples for a in self.moda]\n",
    "\n",
    "            for base in indices_base:\n",
    "\n",
    "                indices.extend(list(range(base, base+self.nb_samples)))\n",
    "\n",
    "            image_moda = image[indices, :, :]\n",
    "\n",
    "            X[i, ] = self.divise_aug(image_moda)\n",
    "\n",
    "        X = X/255\n",
    "\n",
    "        return X\n",
    "\n",
    "    def divise_aug(self, image):\n",
    "\n",
    "        if self.aug:\n",
    "\n",
    "            image = self.augmentation(image)\n",
    "\n",
    "        if self.divise:\n",
    "\n",
    "            X = [image[self.nb_samples*i:self.nb_samples*(i+1), :, :]\n",
    "                 for i in range(len(self.moda))]\n",
    "\n",
    "        else:\n",
    "\n",
    "            X = image\n",
    "\n",
    "        return X\n",
    "\n",
    "    def augmentation(self, im3d):\n",
    "\n",
    "        im3d = self.flip(im3d)\n",
    "        im3d = self.zoom(im3d)\n",
    "        im3d = self.rotate(im3d).astype(np.uint8)\n",
    "\n",
    "        bit_elas = random.getrandbits(1)\n",
    "\n",
    "        if bit_elas:\n",
    "\n",
    "            im3d = self.elastic(im3d)\n",
    "\n",
    "        im3d = self.put_salt(im3d)\n",
    "\n",
    "        return im3d.astype(np.uint8)\n",
    "\n",
    "    def flip(self, image):\n",
    "\n",
    "        bit = random.getrandbits(1)\n",
    "\n",
    "        if bit:\n",
    "\n",
    "            new_image = np.flip(image, axis=2)\n",
    "\n",
    "        else:\n",
    "\n",
    "            new_image = image\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def zoom(self, im3d):\n",
    "\n",
    "        n = round(random.uniform(1, 1.2), 2)\n",
    "        scale = iaa.Affine(scale=(n))\n",
    "\n",
    "        new_image = np.zeros(im3d.shape)\n",
    "\n",
    "        for i in range(im3d.shape[0]):\n",
    "\n",
    "            img = im3d[i, :, :]\n",
    "            img = scale.augment_image(img)\n",
    "            new_image[i] = img\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def rotate(self, im3d):\n",
    "\n",
    "        n = random.randint(-15, 15)\n",
    "        rotation = iaa.geometric.Affine(rotate=n, mode=\"reflect\")\n",
    "\n",
    "        new_image = np.zeros(im3d.shape)\n",
    "\n",
    "        for i in range(im3d.shape[0]):\n",
    "\n",
    "            img = im3d[i, :, :]\n",
    "            img = rotation.augment_image(img)\n",
    "            new_image[i] = img\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def put_salt(self, im3d):\n",
    "\n",
    "        n = np.round(random.uniform(0.00, 0.009), 3)\n",
    "\n",
    "        salt = iaa.arithmetic.Salt(n)\n",
    "\n",
    "        new_image = np.zeros(im3d.shape)\n",
    "\n",
    "        for i in range(im3d.shape[0]):\n",
    "\n",
    "            img = im3d[i, :, :]\n",
    "            img = salt.augment_image(img)\n",
    "            new_image[i] = img\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def elastic(self, im3d):\n",
    "\n",
    "        alp = random.randint(40, 60)\n",
    "        sig = random.randint(20, 40)\n",
    "\n",
    "        new_image = np.zeros_like(im3d)\n",
    "\n",
    "        elastic_tr = iaa.geometric.ElasticTransformation(alpha=alp,\n",
    "                                                         sigma=sig,\n",
    "                                                         mode=\"reflect\")\n",
    "\n",
    "        for i in range(im3d.shape[0]):\n",
    "\n",
    "            img = im3d[i, :, :]\n",
    "            img = elastic_tr.augment_image(img)\n",
    "            new_image[i] = img\n",
    "\n",
    "        return new_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T00:03:20.067787Z",
     "iopub.status.busy": "2021-11-13T00:03:20.067461Z",
     "iopub.status.idle": "2021-11-13T00:03:20.308386Z",
     "shell.execute_reply": "2021-11-13T00:03:20.307600Z",
     "shell.execute_reply.started": "2021-11-13T00:03:20.067743Z"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Modelization function #\n",
    "#########################\n",
    "\n",
    "def modelize_gen(model, train_gen, val_gen, nb_epochs, batch, opti=\"adam\",\n",
    "                 verbose=0, graph=False):\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opti,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        batch_size=batch,\n",
    "                        validation_data=val_gen,\n",
    "                        epochs=nb_epochs,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    train_acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    train_loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    if graph:\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(range(1, nb_epochs+1), train_loss, 'b', label='Train loss',\n",
    "                 color=\"green\")\n",
    "        plt.plot(range(1, nb_epochs+1), val_loss, 'b', label='Validation loss',\n",
    "                 color=\"orange\")\n",
    "        plt.title('Train & validation losses - ')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Losses\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(range(1, nb_epochs+1), train_acc, 'b', label='Train acc',\n",
    "                 color=\"red\")\n",
    "        plt.plot(range(1, nb_epochs+1), val_acc, 'b', label='Validation acc',\n",
    "                 color=\"blue\")\n",
    "        plt.title('Train & validation accuracies - ')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print()\n",
    "        print(f\"Temps d'entrainements pour {nb_epochs} epochs :\\\n",
    "        {time()-start:.0f} secondes.\")\n",
    "        print(f\"Meilleure train_acc = {np.max(train_acc):.3f},\\\n",
    "        meilleure val_acc = {np.max(val_acc):.3f}\")\n",
    "        print()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "##################\n",
    "# Model creation #\n",
    "##################\n",
    "\n",
    "def create_model_4_12_150():\n",
    "\n",
    "    inputs = Input((NB_MOD, NB_SAMPLES, SIZE[0], SIZE[1], 1))\n",
    "\n",
    "    inA = inputs[:, 0, :, :, :]\n",
    "    a = Conv3D(8, kernel_size=3, activation=\"relu\")(inA)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = Conv3D(8, kernel_size=3, activation=\"relu\")(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPool3D(pool_size=2)(a)\n",
    "    a = Conv3D(16, kernel_size=3, activation=\"relu\")(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPool3D(pool_size=2)(a)\n",
    "    a = Reshape((35, 35, 16))(a)\n",
    "    a = Conv2D(32, kernel_size=3, activation=\"relu\")(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPool2D(pool_size=2)(a)\n",
    "    a = Conv2D(32, kernel_size=3, activation=\"relu\")(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPool2D(pool_size=2)(a)\n",
    "    a = Flatten()(a)\n",
    "\n",
    "    inB = inputs[:, 1, :, :, :]\n",
    "    b = Conv3D(8, kernel_size=3, activation=\"relu\")(inB)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = Conv3D(8, kernel_size=3, activation=\"relu\")(b)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPool3D(pool_size=2)(b)\n",
    "    b = Conv3D(16, kernel_size=3, activation=\"relu\")(b)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPool3D(pool_size=2)(b)\n",
    "    b = Reshape((35, 35, 16))(b)\n",
    "    b = Conv2D(32, kernel_size=3, activation=\"relu\")(b)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPool2D(pool_size=2)(b)\n",
    "    b = Conv2D(32, kernel_size=3, activation=\"relu\")(b)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPool2D(pool_size=2)(b)\n",
    "    b = Flatten()(b)\n",
    "\n",
    "    inC = inputs[:, 2, :, :, :]\n",
    "    c = Conv3D(8, kernel_size=3, activation=\"relu\")(inC)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = Conv3D(8, kernel_size=3, activation=\"relu\")(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPool3D(pool_size=2)(c)\n",
    "    c = Conv3D(16, kernel_size=3, activation=\"relu\")(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPool3D(pool_size=2)(c)\n",
    "    c = Reshape((35, 35, 16))(c)\n",
    "    c = Conv2D(32, kernel_size=3, activation=\"relu\")(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPool2D(pool_size=2)(c)\n",
    "    c = Conv2D(32, kernel_size=3, activation=\"relu\")(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPool2D(pool_size=2)(c)\n",
    "    c = Flatten()(c)\n",
    "\n",
    "    inD = inputs[:, 3, :, :, :]\n",
    "    d = BatchNormalization()(inD)\n",
    "    d = Conv3D(8, kernel_size=3, activation=\"relu\")(inD)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Conv3D(8, kernel_size=3, activation=\"relu\")(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPool3D(pool_size=2)(d)\n",
    "    d = Conv3D(16, kernel_size=3, activation=\"relu\")(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPool3D(pool_size=2)(d)\n",
    "    d = Reshape((35, 35, 16))(d)\n",
    "    d = Conv2D(32, kernel_size=3, activation=\"relu\")(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPool2D(pool_size=2)(d)\n",
    "    d = Conv2D(32, kernel_size=3, activation=\"relu\")(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPool2D(pool_size=2)(d)\n",
    "    d = Flatten()(d)\n",
    "\n",
    "    x = Concatenate()([a, b, c, d])\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T00:04:07.605802Z",
     "iopub.status.busy": "2021-11-13T00:04:07.605466Z",
     "iopub.status.idle": "2021-11-13T00:04:07.788834Z",
     "shell.execute_reply": "2021-11-13T00:04:07.787795Z",
     "shell.execute_reply.started": "2021-11-13T00:04:07.605764Z"
    }
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# submission #\n",
    "##############\n",
    "\n",
    "def submission(model, X_test, df_test):\n",
    "    \"\"\"\n",
    "    Create the submission csv file\n",
    "    \"\"\"\n",
    "    preds = model.predict(X_test)\n",
    "    df_test = df_test[df_test[\"scan type\"] == \"FLAIR\"]\n",
    "    df_test[\"MGMT_value\"] = list(np.squeeze(preds))\n",
    "    df_test = df_test[[\"BraTS21ID\", \"MGMT_value\"]]\n",
    "    df_test.to_csv(OUT + \"/\" + \"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "##########    \n",
    "# Script #\n",
    "##########\n",
    "\n",
    "start = time()\n",
    "\n",
    "print(\"Beginning submission script\")\n",
    "df = create_dataframe(TRAIN_PATH, MODS)\n",
    "df_test = create_dataframe(TEST_PATH, MODS)\n",
    "\n",
    "df = filter_train_df(df)\n",
    "dico_labels = create_dicts(INPUT + \"/\" + \"train_labels.csv\")\n",
    "\n",
    "IDs = df[\"BraTS21ID\"].values.tolist()\n",
    "IDs = sorted(list(set(IDs)))\n",
    "train_IDs, val_IDs = train_test_split(IDs, test_size=0.15)\n",
    "\n",
    "df_train = df[df[\"BraTS21ID\"].isin(train_IDs)]\n",
    "df_val = df[df[\"BraTS21ID\"].isin(val_IDs)]\n",
    "\n",
    "print(\"Dataframes created, beginning preprocessing\")\n",
    "\n",
    "preprocessing(df_train, OUT_TRAIN, MODS)\n",
    "preprocessing(df_val, OUT_VAL, MODS)\n",
    "preprocessing(df_test, OUT_TEST, MODS)\n",
    "\n",
    "print(\"Preprocessing ended, preparing data generator\")\n",
    "\n",
    "# Train generator\n",
    "liste_train = sorted(os.listdir(OUT_TRAIN))\n",
    "random.shuffle(liste_train)\n",
    "liste_train_labels = [dico_labels[elt.split(\".\")[0]] for elt in liste_train]\n",
    "\n",
    "param_train = {\"list_IDs\" : liste_train * LIST_ITERATION, \n",
    "               \"labels\" : liste_train_labels * LIST_ITERATION,\n",
    "               \"source\" : OUT_TRAIN, \n",
    "               \"batch_size\" : BATCH,\n",
    "               \"nb_samples\" : 12, \n",
    "               \"moda\" : [0, 1, 2, 3],\n",
    "               \"shuffle\" : True,\n",
    "               \"divise\" : True,\n",
    "               \"aug\" : True,\n",
    "               \"train\" : True}\n",
    "\n",
    "train_gen_4x12_150 = DataGenerator(**param_train)\n",
    "\n",
    "# Validation generator\n",
    "liste_val = sorted(os.listdir(OUT_VAL))\n",
    "random.shuffle(liste_val)\n",
    "liste_val_labels = [dico_labels[elt.split(\".\")[0]] for elt in liste_val]\n",
    "\n",
    "param_val = {\"list_IDs\" : liste_val, \n",
    "               \"labels\" : liste_train_labels,\n",
    "               \"source\" : OUT_VAL, \n",
    "               \"batch_size\" : BATCH,\n",
    "               \"nb_samples\" : 12, \n",
    "               \"moda\" : [0, 1, 2, 3],\n",
    "               \"shuffle\" : True,\n",
    "               \"divise\" : True,\n",
    "               \"aug\" : False,\n",
    "               \"train\" : True}\n",
    "\n",
    "val_gen_4x12_150 = DataGenerator(**param_val)\n",
    "\n",
    "# Test generator\n",
    "liste_test = sorted(os.listdir(OUT_TEST))\n",
    "param_test = {\"list_IDs\" : liste_test,\n",
    "             \"labels\" : None,\n",
    "             \"source\" : OUT_TEST,\n",
    "             \"batch_size\" : 1,\n",
    "             \"nb_samples\" : 12,\n",
    "             \"moda\" : [0, 1, 2, 3],\n",
    "             \"shuffle\" : False,\n",
    "             \"aug\" : False,\n",
    "             \"divise\" : True,\n",
    "             \"train\" : False}\n",
    "\n",
    "test_gen_4x12_150 = DataGenerator(**param_test)\n",
    "\n",
    "print(\"Beginning modelization\")\n",
    "\n",
    "model = create_model_4_12_150()\n",
    "\n",
    "model = modelize_gen(model,\n",
    "                     train_gen_4x12_150,\n",
    "                     val_gen_4x12_150,\n",
    "                     8,\n",
    "                     batch = BATCH,\n",
    "                     opti = \"adam\",\n",
    "                     verbose = 1)\n",
    "\n",
    "print(\"Model training ended, making submission\")\n",
    "\n",
    "submission(model, test_gen_4x12_150, df_test)\n",
    "\n",
    "print(f\"Submission process completed. It took {time()-start:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-13T00:11:29.309949Z",
     "iopub.status.busy": "2021-11-13T00:11:29.309636Z",
     "iopub.status.idle": "2021-11-13T00:11:29.535359Z",
     "shell.execute_reply": "2021-11-13T00:11:29.534376Z",
     "shell.execute_reply.started": "2021-11-13T00:11:29.309913Z"
    }
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# BONUS : Find here two functions to test if the \"zoi identifying #\n",
    "# process\" works, or not. It is needed to create the reference    #\n",
    "# dataframes before using them. See demo below...                 #\n",
    "###################################################################\n",
    "\n",
    "def test_im(name, df_source):\n",
    "    \"\"\"\n",
    "    Give the \"BraTS21ID\" of a patient and the dataframe (df_train, df_val\n",
    "    or df_test) he belongs to.\n",
    "    The function will return the \"zoi\" taken for the modelization.\n",
    "    \"\"\"\n",
    "    row = df_source[(df_source[\"BraTS21ID\"] == name) &\n",
    "                    (df_source[\"scan type\"] == \"FLAIR\")]\n",
    "\n",
    "    path_dcm = row[\"chemins\"].values[0]\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(path_dcm)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    im3D = reader.Execute()\n",
    "    new_img3D = resample(im3D, ref_image)\n",
    "    array_3D = normalize_img(sitk.GetArrayFromImage(new_img3D))\n",
    "    array_3D = resize_3d(array_3D, SIZE_TEMP).astype(np.uint8)\n",
    "\n",
    "    zoi = zoi_cube(array_3D, name)\n",
    "    print(zoi)\n",
    "\n",
    "    slices = zoi[5] - zoi[4]\n",
    "\n",
    "    if slices < NB_SAMPLES:\n",
    "\n",
    "        missing = NB_SAMPLES-slices\n",
    "\n",
    "        extension = int(missing//2)\n",
    "        lim_haute = zoi[4] - extension\n",
    "\n",
    "        if missing % 2 == 0:\n",
    "\n",
    "            lim_basse = zoi[5] + extension\n",
    "\n",
    "        else:\n",
    "\n",
    "            lim_basse = zoi[5] + extension + 1\n",
    "\n",
    "        if lim_haute < 0:\n",
    "\n",
    "            lim_haute = 0\n",
    "            lim_basse = NB_SAMPLES\n",
    "\n",
    "        if lim_basse > array_3D.shape[0] - 1:\n",
    "\n",
    "            lim_basse = array_3D.shape[0] - 1\n",
    "            lim_haute = array_3D.shape[0] - (NB_SAMPLES + 1)\n",
    "\n",
    "    elif slices > NB_SAMPLES:\n",
    "\n",
    "        surplus = slices - NB_SAMPLES\n",
    "\n",
    "        reduction = int(surplus//2)\n",
    "        lim_haute = zoi[4] + reduction\n",
    "\n",
    "        if surplus % 2 == 0:\n",
    "\n",
    "            lim_basse = zoi[5] - reduction\n",
    "\n",
    "        else:\n",
    "\n",
    "            lim_basse = zoi[5] - (reduction + 1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        lim_haute = zoi[4]\n",
    "        lim_basse = zoi[5]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 42))\n",
    "\n",
    "    for i in range(array_3D.shape[0]):\n",
    "\n",
    "        if np.mean(array_3D[i]) != 0:\n",
    "            mask = array_3D[i] > 0\n",
    "            coords = np.argwhere(mask)\n",
    "\n",
    "            y0, x0 = coords.min(axis=0)\n",
    "            y1, x1 = coords.max(axis=0) + 1\n",
    "\n",
    "            haut = y1-y0\n",
    "            larg = x1-x0\n",
    "\n",
    "        else:\n",
    "\n",
    "            haut = 0\n",
    "            larg = 0\n",
    "\n",
    "        titre = f\"ht {haut} {haut/SIZE_TEMP[0]:.2f} - la\\\n",
    "        {larg} {larg/SIZE_TEMP[0]:.2f}\"\n",
    "\n",
    "        dessin = plt.subplot(12, 4, i + 1)\n",
    "        rect = patches.Rectangle((zoi[0], zoi[2]), 150, 150,\n",
    "                                 linewidth=1.5, edgecolor='r',\n",
    "                                 facecolor='none')\n",
    "\n",
    "        if i >= lim_haute and i < lim_basse:\n",
    "\n",
    "            dessin.add_patch(rect)\n",
    "\n",
    "        dessin.title.set_text(titre)\n",
    "        plt.imshow(array_3D[i, :, :])\n",
    "\n",
    "\n",
    "def level_im(name, df_source):\n",
    "    \"\"\"\n",
    "    Same as before but here the function shows the \"bright flattened\" image.\n",
    "    \"\"\"\n",
    "\n",
    "    row = df_source[(df_source[\"BraTS21ID\"] == name) &\n",
    "                    (df_source[\"scan type\"] == \"FLAIR\")]\n",
    "\n",
    "    path_dcm = row[\"chemins\"].values[0]\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(path_dcm)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    im3D = reader.Execute()\n",
    "    new_img3D = resample(im3D, ref_image)\n",
    "    array_3D = normalize_img(sitk.GetArrayFromImage(new_img3D))\n",
    "    array_3D = resize_3d(array_3D, SIZE_TEMP).astype(np.uint8)\n",
    "\n",
    "    rab = rabote(array_3D, 40)\n",
    "\n",
    "    masked = np.ma.masked_equal(rab, 0)\n",
    "    mean_image = np.mean(masked, axis=0).astype(np.uint8)\n",
    "\n",
    "    eroded = cv2.erode(mean_image, None, iterations=5)\n",
    "    eroded = normalize_img(eroded).astype(np.uint8)\n",
    "\n",
    "    masked2 = np.ma.masked_equal(array_3D, 0)\n",
    "    mean_image2 = np.mean(masked2, axis=0).astype(np.uint8)\n",
    "\n",
    "    eroded2 = cv2.erode(mean_image2, None, iterations=5)\n",
    "    eroded2 = normalize_img(eroded2).astype(np.uint8)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(eroded2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:27:12.594744Z",
     "iopub.status.busy": "2021-11-04T10:27:12.594451Z",
     "iopub.status.idle": "2021-11-04T10:27:14.107826Z",
     "shell.execute_reply": "2021-11-04T10:27:14.107166Z",
     "shell.execute_reply.started": "2021-11-04T10:27:12.594716Z"
    }
   },
   "outputs": [],
   "source": [
    "# First create the dataframes\n",
    "\n",
    "df = create_dataframe(TRAIN_PATH, MODS)\n",
    "df_test = create_dataframe(TEST_PATH, MODS)\n",
    "\n",
    "df = filter_train_df(df)\n",
    "dico_labels = create_dicts(INPUT + \"/\" + \"train_labels.csv\")\n",
    "\n",
    "IDs = df[\"BraTS21ID\"].values.tolist()\n",
    "IDs = sorted(list(set(IDs)))\n",
    "train_IDs, val_IDs = train_test_split(IDs, test_size=0.15)\n",
    "\n",
    "df_train = df[df[\"BraTS21ID\"].isin(train_IDs)]\n",
    "df_val = df[df[\"BraTS21ID\"].isin(val_IDs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:35:17.110617Z",
     "iopub.status.busy": "2021-11-04T10:35:17.110123Z",
     "iopub.status.idle": "2021-11-04T10:35:17.117055Z",
     "shell.execute_reply": "2021-11-04T10:35:17.116075Z",
     "shell.execute_reply.started": "2021-11-04T10:35:17.110566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now choose one dataframe and a \"BraTS21ID\" in it.\n",
    "print(set(df_train[\"BraTS21ID\"].values.tolist()[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:37:20.679772Z",
     "iopub.status.busy": "2021-11-04T10:37:20.679149Z",
     "iopub.status.idle": "2021-11-04T10:37:31.158403Z",
     "shell.execute_reply": "2021-11-04T10:37:31.157528Z",
     "shell.execute_reply.started": "2021-11-04T10:37:20.679736Z"
    }
   },
   "outputs": [],
   "source": [
    "# And use a function with a \"BraTS21ID\".\n",
    "# It will plot all the slices of a reoriented 3d image and show\n",
    "# in the red squares what exactly was kept for\n",
    "# modelizations...\n",
    "\n",
    "name = \"00022\"\n",
    "ref_df = df_train\n",
    "\n",
    "test_im(name, ref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:37:31.160733Z",
     "iopub.status.busy": "2021-11-04T10:37:31.160225Z",
     "iopub.status.idle": "2021-11-04T10:37:33.966141Z",
     "shell.execute_reply": "2021-11-04T10:37:33.965544Z",
     "shell.execute_reply.started": "2021-11-04T10:37:31.160690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flattened version\n",
    "level_im(name, ref_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
